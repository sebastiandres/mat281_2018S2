{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configuracion para recargar módulos y librerías \n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Configuración para plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT281 - Laboratorio 9\n",
    "\n",
    "## Aplicaciones de la Matemática en la Ingeniería\n",
    "\n",
    "Puedes ejecutar este jupyter notebook de manera interactiva:\n",
    "\n",
    "[![Binder](../shared/images/jupyter_binder.png)](https://mybinder.org/v2/gh/sebastiandres/mat281_m04_data_science/master?filepath=/07_lab_clustering//07_lab_clustering.ipynb)\n",
    "\n",
    "[![Colab](../shared/images/jupyter_colab.png)](https://colab.research.google.com/github/sebastiandres/mat281_m04_data_science/blob/master///07_lab_clustering//07_lab_clustering.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Intrucciones__\n",
    "\n",
    "* Completa tus datos personales (nombre y rol USM).\n",
    "* Debes enviar este .ipynb con el siguiente formato de nombre: 08_lab_clasificacion_NOMBRE_APELLIDO.ipynb con tus respuestas a alonso.ogueda@gmail.com y sebastian.flores@usm.cl .\n",
    "* Se evaluará:\n",
    "    - Soluciones\n",
    "    - Código\n",
    "    - Al presionar  `Kernel -> Restart Kernel and Run All Cells` deben ejecutarse todas las celdas sin error.\n",
    "    - La escala es de 0 a 4 considerando solo valores enteros.\n",
    "* __La entrega es al final de esta clase.__\n",
    "\n",
    "__Nombre__:\n",
    "\n",
    "__Rol__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observación\n",
    "\n",
    "***Este laboratorio utiliza la librería sklearn (oficialmente llamada [scikit learn](http://scikit-learn.org/stable/)), puesto que buscamos aplicar la técnica del clustering a datos tal como se haría en una aplicación real. El código a proveer en este laboratorio es reducido, y la nota se basará mayoritariamente en la calidad de las respuestas entregadas en los comentarios.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema: Wine Dataset\n",
    "\n",
    "Los datos del [Wine Dataset](https://archive.ics.uci.edu/ml/datasets/Wine) son un conjunto de datos clásicos para verificar los algoritmos de clustering. \n",
    "\n",
    "<img src=\"images/wine.jpg\" alt=\"\" width=\"600px\" align=\"middle\"/>\n",
    "\n",
    "Los datos corresponden a 3 cultivos diferentes de vinos de la misma región de Italia, y que han sido identificados con las etiquetas 1, 2 y 3. Para cada tipo de vino han sido realizados 13 análisis químicos:\n",
    "\n",
    "1. Alcohol \n",
    "2. Malic acid \n",
    "3. Ash \n",
    "4. Alcalinity of ash \n",
    "5. Magnesium \n",
    "6. Total phenols \n",
    "7. Flavanoids \n",
    "8. Nonflavanoid phenols \n",
    "9. Proanthocyanins \n",
    "10. Color intensity \n",
    "11. Hue \n",
    "12. OD280/OD315 of diluted wines \n",
    "13. Proline \n",
    "\n",
    "\n",
    "La base de datos contiene 178 muestras distintas en total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Entendimiento del dataset\n",
    "Antes de leer los datos y aplicar algoritmos, resulta importante comprender la naturaleza de los datos. Los datos del wine dataset ya se encuentan en la carpeta `data/`. \n",
    "\n",
    "Existen 2 archivos de interés:\n",
    "* `wine_data.txt` : Datos de interés.\n",
    "* `wine_names.txt` : Explicación de los datos.\n",
    "\n",
    "Lea atentamente el archivo `wine_names.txt` y responda las preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title of Database: Wine recognition data\n",
      "\tUpdated Sept 21, 1998 by C.Blake : Added attribute information\n",
      "\n",
      "2. Sources:\n",
      "   (a) Forina, M. et al, PARVUS - An Extendible Package for Data\n",
      "       Exploration, Classification and Correlation. Institute of Pharmaceutical\n",
      "       and Food Analysis and Technologies, Via Brigata Salerno, \n",
      "       16147 Genoa, Italy.\n",
      "\n",
      "   (b) Stefan Aeberhard, email: stefan@coral.cs.jcu.edu.au\n",
      "   (c) July 1991\n",
      "3. Past Usage:\n",
      "\n",
      "   (1)\n",
      "   S. Aeberhard, D. Coomans and O. de Vel,\n",
      "   Comparison of Classifiers in High Dimensional Settings,\n",
      "   Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\n",
      "   Mathematics and Statistics, James Cook University of North Queensland.\n",
      "   (Also submitted to Technometrics).\n",
      "\n",
      "   The data was used with many others for comparing various \n",
      "   classifiers. The classes are separable, though only RDA \n",
      "   has achieved 100% correct classification.\n",
      "   (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\n",
      "   (All results using the leave-one-out technique)\n",
      "\n",
      "   In a classification context, this is a well posed problem \n",
      "   with \"well behaved\" class structures. A good data set \n",
      "   for first testing of a new classifier, but not very \n",
      "   challenging.\n",
      "\n",
      "   (2) \n",
      "   S. Aeberhard, D. Coomans and O. de Vel,\n",
      "   \"THE CLASSIFICATION PERFORMANCE OF RDA\"\n",
      "   Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\n",
      "   Mathematics and Statistics, James Cook University of North Queensland.\n",
      "   (Also submitted to Journal of Chemometrics).\n",
      "\n",
      "   Here, the data was used to illustrate the superior performance of\n",
      "   the use of a new appreciation function with RDA. \n",
      "\n",
      "4. Relevant Information:\n",
      "\n",
      "   -- These data are the results of a chemical analysis of\n",
      "      wines grown in the same region in Italy but derived from three\n",
      "      different cultivars.\n",
      "      The analysis determined the quantities of 13 constituents\n",
      "      found in each of the three types of wines. \n",
      "\n",
      "   -- I think that the initial data set had around 30 variables, but \n",
      "      for some reason I only have the 13 dimensional version. \n",
      "      I had a list of what the 30 or so variables were, but a.) \n",
      "      I lost it, and b.), I would not know which 13 variables\n",
      "      are included in the set.\n",
      "\n",
      "   -- The attributes are (dontated by Riccardo Leardi, \n",
      "\triclea@anchem.unige.it )\n",
      " \t1) Alcohol\n",
      " \t2) Malic acid\n",
      " \t3) Ash\n",
      "\t4) Alcalinity of ash  \n",
      " \t5) Magnesium\n",
      "\t6) Total phenols\n",
      " \t7) Flavanoids\n",
      " \t8) Nonflavanoid phenols\n",
      " \t9) Proanthocyanins\n",
      "\t10)Color intensity\n",
      " \t11)Hue\n",
      " \t12)OD280/OD315 of diluted wines\n",
      " \t13)Proline            \n",
      "\n",
      "5. Number of Instances\n",
      "\n",
      "      \tclass 1 59\n",
      "\tclass 2 71\n",
      "\tclass 3 48\n",
      "\n",
      "6. Number of Attributes \n",
      "\t\n",
      "\t13\n",
      "\n",
      "7. For Each Attribute:\n",
      "\n",
      "\tAll attributes are continuous\n",
      "\t\n",
      "\tNo statistics available, but suggest to standardise\n",
      "\tvariables for certain uses (e.g. for us with classifiers\n",
      "\twhich are NOT scale invariant)\n",
      "\n",
      "\tNOTE: 1st attribute is class identifier (1-3)\n",
      "\n",
      "8. Missing Attribute Values:\n",
      "\n",
      "\tNone\n",
      "\n",
      "9. Class Distribution: number of instances per class\n",
      "\n",
      "      \tclass 1 59\n",
      "\tclass 2 71\n",
      "\tclass 3 48\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat data/wine_names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1.1\n",
    "¿Que contiene el archivo? Describa su contenido de manera que una tercera persona, que no ha visto la descripción, pueda entenderlo.\n",
    "\n",
    "*R:* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1.2\n",
    "¿**Porqué** y **cómo** podemos usar este dataset para probar algoritmos de clustering cuando los datos han sido usados para algoritmos de clasificación?\n",
    "\n",
    "*R:* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder, miremos algunas lineas del archivo a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head data/wine_data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código permite leer los datos desde el archivo `data/wine_data.txt` y cargarlos en un dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine_class</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wine_class  alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  \\\n",
       "0           1    14.23        1.71  2.43               15.6        127   \n",
       "1           1    13.20        1.78  2.14               11.2        100   \n",
       "2           1    13.16        2.36  2.67               18.6        101   \n",
       "3           1    14.37        1.95  2.50               16.8        113   \n",
       "4           1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   color_intensity   hue  OD280/OD315  proline  \n",
       "0             5.64  1.04         3.92     1065  \n",
       "1             4.38  1.05         3.40     1050  \n",
       "2             5.68  1.03         3.17     1185  \n",
       "3             7.80  0.86         3.45     1480  \n",
       "4             4.32  1.04         2.93      735  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "names = [\"alcohol\", \"malic_acid\", \"ash\", \"alcalinity_of_ash\", \"magnesium\", \"total_phenols\",\n",
    "         \"flavanoids\", \"nonflavanoid_phenols\", \"proanthocyanins\", \"color_intensity\",\n",
    "         \"hue\", \"OD280/OD315\", \"proline\"]\n",
    "columns = [\"wine_class\"] + names\n",
    "filename = os.path.join(\"data\",\"wine_data.txt\")\n",
    "df = pd.read_csv(filename, names=columns, sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2\n",
    "Complete la preparación de los datos, separando los datos en un dataframe `X` (datos a utilizar para clustering) y una serie `true_labels` (etiquetas verdaderas para cada dato de `X`).\n",
    "\n",
    "\n",
    "**OBSERVACION**: La serie `true_labels` debe modificarse para que sean 0, 1 y 2 (en vez de 1, 2 y 3 como vienen en el archivo), porque el algoritmo de clustering asume que las categorías se numeran desde 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Seleccionar X\n",
    "X = df # FIX ME ¿que columnas tomar?\n",
    "\n",
    "# Seleccionar true_labels\n",
    "true_labels = df # FIX ME ¿que columna tomar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check true_labels\n",
    "true_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3\n",
    "Utilizando la serie `true_labels` definido anteriormente, complete el código para conocer cuántas muestras son de tipo 0, de tipo 1 y de tipo 2. Compare con lo indicado en el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Es muy util saber contar valores en una serie de pandas.\n",
    "# Porque permite responder esta pregunta con 1 linea\n",
    "vc = 0 # FIX ME\n",
    "\n",
    "print(vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploración de valores\n",
    "\n",
    "Antes de realizar el clustering, deseamos revisar los datos. El siguiente código permite conocer la distribución de las mediciones para las muestras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "rows, cols = 5, 3\n",
    "fig1, axes1 = plt.subplots(rows, cols, figsize=(16,16))\n",
    "for i in range(rows):\n",
    "    for  j in range(cols):\n",
    "        n = i*cols + j\n",
    "        if n<13:\n",
    "            ax = axes1[i][j]\n",
    "            col_name = names[n]\n",
    "            ax.hist(X[col_name], alpha=0.50)\n",
    "            ax.set_title(col_name)\n",
    "fig1.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O, aprovechando las ventajas de usar la librería pandas, \n",
    "podemos utilizar los métodos nativos para obtener el mismo resultado con mucho menor esfuerzo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "rows, cols = 5, 3\n",
    "fig2, axes2 = plt.subplots(rows, cols, figsize=(16,16))\n",
    "for n, col_name in enumerate(names):\n",
    "    ax = axes2[n//cols][n%cols]\n",
    "    df[col_name].hist(bins=12, alpha=0.50, ax=ax)\n",
    "    ax.set_title(col_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O, incluso como no son demasiadas variables, podemos graficar todas las relaciones con scatter_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paciencia - tomará 30 segundos.\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(df, alpha=0.25, figsize=(20, 20), diagonal='hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 4\n",
    "\n",
    "En base a la exploración de valores, usted:\n",
    "1. Aplicaría el algoritmo de clustering directamente.\n",
    "2. Realizaría algún tipo de normalización a los datos, y luego aplicar el algoritmo de clustering.\n",
    "\n",
    "¿Que resulta más razonable, opción 1 u opción 2? ¿Porqué?\n",
    "\n",
    "**Justifique su respuesta**: piense en cómo funciona K-Means.\n",
    "\n",
    "#### Respuesta\n",
    "\n",
    "*R:* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering Directo\n",
    "\n",
    "A continuación se provee el código para realizar el clustering de los datos de manera directa (sin normalizar). Recuerde que el algoritmo hará predicción de clusters y no de etiquetas, por lo que la matriz de confusión no necesariamente será diagonal. Para la interpretación de la matriz de confusión, considere la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Parameters\n",
    "n_clusters = 3\n",
    "\n",
    "# Running the algorithm\n",
    "kmeans = KMeans(n_clusters)\n",
    "kmeans.fit(X)\n",
    "pred_labels = kmeans.labels_\n",
    "\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 5\n",
    "\n",
    "Ejecute el código anterior y comente los resultados. ¿Permite el clustering recobrar el agrupamiento natural de los datos? ¿Si no, porqué?\n",
    "\n",
    "#### Respuesta\n",
    "\n",
    "*R:* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalización de los datos\n",
    "\n",
    "Sabemos que los algoritmos suelen funcionar mejor con los datos normalizados, como se explicó en la clase de Regresión Lineal. Note que en el caso de los algoritmos de clustering, sólo es necesario normalizar la matrix `X`, ¡las etiquetas no necesitan normalizarse!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 6.1\n",
    "Normalice los datos utilizando para obtener una nueva matriz `X_normalized_1`, cuyas columnas tengan sus datos en el rango [0,1]. \n",
    "\n",
    "**Observación**: Utilice sus conocimientos matemáticos y opere normalmente con `X.max()` y `X.min()`. La respuesta toma 1 línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_normalized_1 = X # FIX ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check facil con el método describe\n",
    "X_normalized_1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 6.2 \n",
    "Reutilice el código anteriormente provisto para realizar el clustering en los datos normalizados y comente los resultados obtenidos. ¿Cuantos errores existen en total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGREGAR CODIGO PARA REALIZAR CLUSTERING EN X_normalized_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario a los resultados obtenidos.\n",
    "\n",
    "*R:* \n",
    "\n",
    "La clasificación es perfecta para la etiquetas originales 1 y 3 (0 y 2 después de re-etiquetar). Se obtiene una clasificación  con 8 errores del total de 71 para la etiqueta 2 (1 depués de re-etiquetar). La normalización mejora muchísimo el desempeño del algoritmo de clustering.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nueva normalización de datos\n",
    "\n",
    "Como usted ya posee cierta experiencia en ajustar modelos, se pregunta si resultará mejor normalizar considerando ahora que cada columna posea media $0$ y desviación estándar $1$ para cada una de sus columnas.\n",
    "\n",
    "### Pregunta 7.1 \n",
    "Estandarice los datos para obtener una nueva matriz `X_normalized_2`, de manera que `X_normalized_2` posea media 0 y desviación estándar 1 para cada una de sus columnas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_mod_2 = X # FIX ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check facil con método describe\n",
    "X_normalized_2.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 7.2\n",
    "Reutilice el código anteriormente provisto para realizar el clustering en los datos estandarizados y comente los resultados obtenidos. ¿Cuantos errores existen en total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGREGAR CODIGO PARA REALIZAR CLUSTERING EN X_normalized_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario a los resultados obtenidos.\n",
    "\n",
    "*R:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 8\n",
    "\n",
    "¿Cuál de las 3 versiones aplicadas de clustering funcionó mejor? ¿Porqué cree que sea así?\n",
    "\n",
    "*R:* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Track: Regla del codo\n",
    "En todos los casos hemos utilizado que el número de clusters es igual a 3. El ajuste del modelo siempre será mejor al aumentar el número de clusters, pero ello no significa que el número de clusters sea el apropiado. De hecho, si tenemos que ajustar $n$ puntos, claramente tomar $n$ clusters generaría un ajuste perfecto, pero no permitiría representar si existen realmente agrupaciones de datos.\n",
    "\n",
    "Cuando no se conoce el número de clusters a priori, se utiliza la [regla del codo](https://jarroba.com/seleccion-del-numero-optimo-clusters/), que indica que el número más apropiado es aquel donde \"cambia la pendiente\" de decrecimiento de la la suma de las distancias a los clusters para cada punto, en función del número de clusters.\n",
    "\n",
    "A continuación se provee el código para el caso de clustering sobre los datos estandarizados, leídos directamente de un archivo preparado especialmente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_mod = np.loadtxt(\"data/X_estandarized.txt\")\n",
    "\n",
    "clusters = range(1,20)\n",
    "total_distance = []\n",
    "for n_clusters in clusters:\n",
    "    kmeans = KMeans(n_clusters)\n",
    "    kmeans.fit(X_mod)\n",
    "    pred_labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    # Get the distances\n",
    "    distance_for_n = 0\n",
    "    for k in range(n_clusters):\n",
    "        points = X_mod[pred_labels==k]\n",
    "        aux = (points - centroids[k,:])**2\n",
    "        distance_for_n += (aux.sum(axis=1)**0.5).sum()\n",
    "    total_distance.append(distance_for_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.plot(clusters, total_distance, 'rs')\n",
    "plt.xlim(min(clusters)-1, max(clusters)+1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
